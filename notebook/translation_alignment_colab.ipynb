{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72833f70",
   "metadata": {},
   "source": [
    "# Translation Adequacy via Centered-Euclidean KL (Colab)\n",
    "This notebook evaluates how close **translated items (JP)** are to their **original items (EN)** using **open-weight multilingual embeddings** and a **centered-Euclidean approximation to KL**.\n",
    "\n",
    "**Pipeline**\n",
    "1. Install & import libraries\n",
    "2. Load your scale items (EN + JP-LLM + JP-HUMAN)\n",
    "3. Embed with one or more open models\n",
    "4. ZCA-whiten per model and optionally align to a reference via orthogonal Procrustes\n",
    "5. Compute item-level **KL≈½·||Δ||²**, cosine similarities, and **quantile indices** versus a negative baseline\n",
    "6. Paired tests (LLM vs HUMAN), cross-model agreement (Spearman, ICC)\n",
    "7. Visualize distributions and a 2D MDS map of versions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd111215",
   "metadata": {},
   "source": [
    "## 1) Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce01c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip -q install sentence-transformers umap-learn scikit-learn scipy matplotlib pandas numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168f55db",
   "metadata": {},
   "source": [
    "## 2) Imports & helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e7f114",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, math, json, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import List, Dict, Tuple\n",
    "from pathlib import Path\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.manifold import MDS\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from scipy.stats import spearmanr, ttest_rel, wilcoxon\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "SEED = 2025\n",
    "random.seed(SEED); np.random.seed(SEED)\n",
    "\n",
    "def l2_normalize(x):\n",
    "    n = np.linalg.norm(x, axis=-1, keepdims=True) + 1e-12\n",
    "    return x / n\n",
    "\n",
    "def cosine_sim(a, b):\n",
    "    a = l2_normalize(a); b = l2_normalize(b)\n",
    "    return (a*b).sum(-1)\n",
    "\n",
    "def zca_whitener(X, eps=1e-6):\n",
    "    mu = X.mean(0, keepdims=True)\n",
    "    Xc = X - mu\n",
    "    C = np.cov(Xc, rowvar=False)\n",
    "    U, s, Vt = np.linalg.svd(C, full_matrices=False)\n",
    "    W = (U @ np.diag(1.0/np.sqrt(s + eps)) @ U.T)\n",
    "    return mu, W\n",
    "\n",
    "def orthogonal_procrustes(X, Y):\n",
    "    Xc = X - X.mean(0, keepdims=True)\n",
    "    Yc = Y - Y.mean(0, keepdims=True)\n",
    "    U, _, Vt = np.linalg.svd(Xc.T @ Yc, full_matrices=False)\n",
    "    R = U @ Vt\n",
    "    return R\n",
    "\n",
    "def half_sqeuclid(a, b):\n",
    "    d = a - b\n",
    "    return 0.5 * float((d*d).sum())\n",
    "\n",
    "def icc2_1(X):\n",
    "    X = np.asarray(X, float)\n",
    "    n, k = X.shape\n",
    "    mean_rows = X.mean(axis=1, keepdims=True)\n",
    "    mean_cols = X.mean(axis=0, keepdims=True)\n",
    "    grand = X.mean()\n",
    "    MSR = k * ((mean_rows - grand)**2).sum() / (n-1)\n",
    "    MSC = n * ((mean_cols - grand)**2).sum() / (k-1)\n",
    "    MSE = ((X - mean_rows - mean_cols + grand)**2).sum() / ((n-1)*(k-1))\n",
    "    icc = (MSR - MSE) / (MSR + (k-1)*MSE + k*(MSC - MSE)/n)\n",
    "    return float(icc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3289a2a9",
   "metadata": {},
   "source": [
    "## 3) Load your data\n",
    "Upload or construct a DataFrame with **one scale** for now. Required columns:\n",
    "- `item_id` (pairs EN↔JP by this id)\n",
    "- `lang` in `{en, ja}`\n",
    "- `trans_type` in `{llm, human}` (JP rows must indicate which)\n",
    "- `text` (the item string)\n",
    "\n",
    "If you don't have a CSV yet, run the sample cell below and edit inline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d293a66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_SAMPLE = True  # set to False and use the upload cell below\n",
    "\n",
    "if USE_SAMPLE:\n",
    "    data = [\n",
    "        {\"item_id\":1,\"lang\":\"en\",\"trans_type\":\"origin\",\"text\":\"On the whole I am satisfied with myself.\"},\n",
    "        {\"item_id\":2,\"lang\":\"en\",\"trans_type\":\"origin\",\"text\":\"At times I think I am no good at all.\"},\n",
    "        {\"item_id\":3,\"lang\":\"en\",\"trans_type\":\"origin\",\"text\":\"I feel that I have a number of good qualities.\"},\n",
    "        {\"item_id\":4,\"lang\":\"en\",\"trans_type\":\"origin\",\"text\":\"I am able to do things as well as most other people.\"},\n",
    "        {\"item_id\":5,\"lang\":\"en\",\"trans_type\":\"origin\",\"text\":\"I feel I do not have much to be proud of.\"},\n",
    "        {\"item_id\":1,\"lang\":\"ja\",\"trans_type\":\"llm\",\"text\":\"概して私は自分に満足している。\"},\n",
    "        {\"item_id\":2,\"lang\":\"ja\",\"trans_type\":\"llm\",\"text\":\"時々、私はまったくダメだと思うことがある。\"},\n",
    "        {\"item_id\":3,\"lang\":\"ja\",\"trans_type\":\"llm\",\"text\":\"私は多くの長所があると感じる。\"},\n",
    "        {\"item_id\":4,\"lang\":\"ja\",\"trans_type\":\"llm\",\"text\":\"私は他の人と同じくらい物事をうまくこなせる。\"},\n",
    "        {\"item_id\":5,\"lang\":\"ja\",\"trans_type\":\"llm\",\"text\":\"誇れるものはあまりないと感じる。\"},\n",
    "        {\"item_id\":1,\"lang\":\"ja\",\"trans_type\":\"human\",\"text\":\"概して、私は自分自身に満足している。\"},\n",
    "        {\"item_id\":2,\"lang\":\"ja\",\"trans_type\":\"human\",\"text\":\"時々、私は全く価値がないのではないかと思う。\"},\n",
    "        {\"item_id\":3,\"lang\":\"ja\",\"trans_type\":\"human\",\"text\":\"私は自分には多くの良い点があると感じる。\"},\n",
    "        {\"item_id\":4,\"lang\":\"ja\",\"trans_type\":\"human\",\"text\":\"私は多くの人と同程度に物事をうまく行える。\"},\n",
    "        {\"item_id\":5,\"lang\":\"ja\",\"trans_type\":\"human\",\"text\":\"誇れるものがあまりないと感じる。\"},\n",
    "    ]\n",
    "    df = pd.DataFrame(data)\n",
    "else:\n",
    "    # from google.colab import files\n",
    "    # up = files.upload()\n",
    "    # fname = list(up.keys())[0]\n",
    "    # df = pd.read_csv(fname)\n",
    "    raise RuntimeError(\"Set USE_SAMPLE=True or use upload.\")\n",
    "\n",
    "assert set(['item_id','lang','trans_type','text']).issubset(df.columns), \"Missing required columns.\"\n",
    "df = df.copy()\n",
    "df['item_id'] = df['item_id'].astype(str)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabb2df6",
   "metadata": {},
   "source": [
    "## 4) Choose models & anchors\n",
    "- Add/remove open-weight models as needed.\n",
    "- For whitening & alignment, we'll use **all rows** as the anchor distribution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd248564",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS = [\n",
    "    (\"labse\", \"sentence-transformers/LaBSE\"),\n",
    "    (\"mE5\",   \"intfloat/multilingual-e5-large\"),\n",
    "]\n",
    "DEVICE = None  # e.g., 'cuda' on Colab if GPU is enabled\n",
    "CACHE_DIR = Path(\"/content/emb_cache\"); CACHE_DIR.mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d255ec1",
   "metadata": {},
   "source": [
    "## 5) Embed all texts (with caching)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5673be88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_model(model_name, model_ckpt, texts, device=None, batch_size=64):\n",
    "    cache_path = CACHE_DIR / f\"{model_name}_cache.npy\"\n",
    "    cache_index = CACHE_DIR / f\"{model_name}_index.json\"\n",
    "    if cache_path.exists() and cache_index.exists():\n",
    "        with open(cache_index, \"r\") as f:\n",
    "            idx_map = json.load(f)\n",
    "        if idx_map.get(\"texts\") == texts:\n",
    "            E = np.load(cache_path)\n",
    "            return E\n",
    "    model = SentenceTransformer(model_ckpt, device=device) if device else SentenceTransformer(model_ckpt)\n",
    "    E = model.encode(texts, convert_to_numpy=True, batch_size=batch_size, show_progress_bar=True, normalize_embeddings=False)\n",
    "    np.save(cache_path, E.astype(np.float32))\n",
    "    with open(cache_index, \"w\") as f:\n",
    "        json.dump({\"texts\": texts}, f)\n",
    "    return E\n",
    "\n",
    "texts = df['text'].tolist()\n",
    "model_vecs = {}\n",
    "for name, ckpt in MODELS:\n",
    "    print(f\"Embedding with {name} ({ckpt}) ...\")\n",
    "    E = embed_model(name, ckpt, texts, device=DEVICE)\n",
    "    model_vecs[name] = E\n",
    "print(\"Done.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d64878",
   "metadata": {},
   "source": [
    "## 6) ZCA-whiten per model and align to a reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a5b82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor_idx = np.arange(len(texts))\n",
    "whitened = {}\n",
    "centers = {}\n",
    "whiteners = {}\n",
    "for name, _ in MODELS:\n",
    "    X = model_vecs[name]\n",
    "    mu, W = zca_whitener(X[anchor_idx])\n",
    "    Xw = (X - mu) @ W.T\n",
    "    whitened[name] = Xw\n",
    "    centers[name] = mu\n",
    "    whiteners[name] = W\n",
    "\n",
    "ref_name = MODELS[0][0]\n",
    "Xref = whitened[ref_name]\n",
    "aligned = {ref_name: Xref.copy()}\n",
    "for name, _ in MODELS[1:]:\n",
    "    Xm = whitened[name]\n",
    "    R = orthogonal_procrustes(Xm[anchor_idx], Xref[anchor_idx])\n",
    "    aligned[name] = Xm @ R\n",
    "print(\"Whitening + alignment complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27681295",
   "metadata": {},
   "source": [
    "## 7) Compute item-level metrics (KL≈½·||Δ||², cosine, quantiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0c9f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_df = df[df['lang']==\"en\"].copy()\n",
    "jp_llm = df[(df['lang']==\"ja\") & (df['trans_type']==\"llm\")].copy()\n",
    "jp_hum = df[(df['lang']==\"ja\") & (df['trans_type']==\"human\")].copy()\n",
    "\n",
    "common_ids_llm = sorted(set(en_df['item_id']) & set(jp_llm['item_id']))\n",
    "common_ids_hum = sorted(set(en_df['item_id']) & set(jp_hum['item_id']))\n",
    "\n",
    "def make_index_map(sub):\n",
    "    return {row.item_id: row.Index for row in sub.reset_index().itertuples()}\n",
    "\n",
    "idx_en   = make_index_map(en_df)\n",
    "idx_llm  = make_index_map(jp_llm)\n",
    "idx_hum  = make_index_map(jp_hum)\n",
    "\n",
    "records = []\n",
    "\n",
    "def neg_baseline_quantiles(X, pos_pairs, n_draws=200):\n",
    "    if not pos_pairs:\n",
    "        return np.array([]), np.array([])\n",
    "    en_idx = [i for i, _ in pos_pairs]\n",
    "    jp_idx = [j for _, j in pos_pairs]\n",
    "    sims_pos = cosine_sim(X[en_idx], X[jp_idx])\n",
    "    neg_scores = []\n",
    "    for _ in range(n_draws):\n",
    "        perm = np.random.permutation(len(jp_idx))\n",
    "        neg_scores.append(cosine_sim(X[en_idx], X[jp_idx][perm]))\n",
    "    neg_scores = np.concatenate(neg_scores)\n",
    "    neg_sorted = np.sort(neg_scores)\n",
    "    ranks = np.searchsorted(neg_sorted, sims_pos, side=\"right\")\n",
    "    quant = ranks / max(1, len(neg_scores))\n",
    "    return sims_pos, quant\n",
    "\n",
    "for name, _ in MODELS:\n",
    "    X = aligned[name]\n",
    "    pos_llm = [(idx_en[iid], idx_llm[iid]) for iid in common_ids_llm]\n",
    "    pos_hum = [(idx_en[iid], idx_hum[iid]) for iid in common_ids_hum]\n",
    "    sims_llm, q_llm = neg_baseline_quantiles(X, pos_llm)\n",
    "    sims_hum, q_hum = neg_baseline_quantiles(X, pos_hum)\n",
    "    def kl_list(pairs):\n",
    "        return np.array([0.5 * np.sum((X[ie] - X[ij])**2) for (ie, ij) in pairs], float)\n",
    "    kl_llm = kl_list(pos_llm) if pos_llm else np.array([])\n",
    "    kl_hum = kl_list(pos_hum) if pos_hum else np.array([])\n",
    "    for k, iid in enumerate(common_ids_llm):\n",
    "        records.append({\"model\": name, \"item_id\": iid, \"trans_type\":\"llm\",\n",
    "                        \"cosine\": float(sims_llm[k]), \"quantile\": float(q_llm[k]), \"kl_half\": float(kl_llm[k])})\n",
    "    for k, iid in enumerate(common_ids_hum):\n",
    "        records.append({\"model\": name, \"item_id\": iid, \"trans_type\":\"human\",\n",
    "                        \"cosine\": float(sims_hum[k]), \"quantile\": float(q_hum[k]), \"kl_half\": float(kl_hum[k])})\n",
    "\n",
    "res = pd.DataFrame(records)\n",
    "res\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e1c4d4",
   "metadata": {},
   "source": [
    "## 8) Paired tests: LLM vs Human (per model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6fb75b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def paired_compare(df_model):\n",
    "    t_llm = df_model[df_model['trans_type']==\"llm\"].set_index(\"item_id\")\n",
    "    t_hum = df_model[df_model['trans_type']==\"human\"].set_index(\"item_id\")\n",
    "    inter = sorted(set(t_llm.index) & set(t_hum.index))\n",
    "    if not inter:\n",
    "        return None\n",
    "    A = t_llm.loc[inter]\n",
    "    B = t_hum.loc[inter]\n",
    "    out = {}\n",
    "    for metric in [\"cosine\", \"quantile\", \"kl_half\"]:\n",
    "        a = A[metric].values\n",
    "        b = B[metric].values\n",
    "        try:\n",
    "            tval, tp = ttest_rel(a, b, nan_policy=\"omit\")\n",
    "        except Exception:\n",
    "            tval, tp = (np.nan, np.nan)\n",
    "        try:\n",
    "            wstat, wp = wilcoxon(a, b, zero_method=\"wilcox\", alternative=\"two-sided\", method=\"auto\")\n",
    "        except Exception:\n",
    "            wstat, wp = (np.nan, np.nan)\n",
    "        out[metric] = {\"n\": len(inter),\n",
    "                       \"mean(llm)\": float(np.mean(a)), \"mean(human)\": float(np.mean(b)),\n",
    "                       \"t\": float(tval), \"t_p\": float(tp),\n",
    "                       \"w\": float(wstat), \"w_p\": float(wp)}\n",
    "    return out\n",
    "\n",
    "summary_rows = []\n",
    "for name, _ in MODELS:\n",
    "    dfm = res[res['model']==name].copy()\n",
    "    stats = paired_compare(dfm)\n",
    "    if stats is None:\n",
    "        continue\n",
    "    for metric, d in stats.items():\n",
    "        summary_rows.append({\"model\": name, \"metric\": metric, **d})\n",
    "pd.DataFrame(summary_rows)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa89fa0",
   "metadata": {},
   "source": [
    "## 9) Cross-model agreement (Spearman, ICC) on item-level KL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8cadb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tbl = res.pivot_table(index=[\"item_id\",\"trans_type\"], columns=\"model\", values=\"kl_half\")\n",
    "tbl = tbl.dropna()\n",
    "models = list(tbl.columns)\n",
    "S = np.zeros((len(models), len(models)))\n",
    "for i, m1 in enumerate(models):\n",
    "    for j, m2 in enumerate(models):\n",
    "        rho, _ = spearmanr(tbl[m1], tbl[m2])\n",
    "        S[i,j] = rho\n",
    "icc = icc2_1(tbl.values)\n",
    "print(\"Models:\", models)\n",
    "print(\"Spearman agreement matrix:\\n\", np.round(S,3))\n",
    "print(\"ICC(2,1) on KL across models:\", round(float(icc), 3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b2af4e",
   "metadata": {},
   "source": [
    "## 10) Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d7a51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (a) Distribution of KL per translation type for the first model\n",
    "first_model = MODELS[0][0]\n",
    "dfm = res[res['model']==first_model]\n",
    "fig = plt.figure(figsize=(6,4))\n",
    "vals_llm = dfm[dfm['trans_type']==\"llm\"][\"kl_half\"].values\n",
    "vals_hum = dfm[dfm['trans_type']==\"human\"][\"kl_half\"].values\n",
    "plt.boxplot([vals_llm, vals_hum], labels=[\"LLM\", \"Human\"])\n",
    "plt.ylabel(\"KL (≈ 0.5 * ||Δ||²)\")\n",
    "plt.title(f\"KL by translation type — {first_model}\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b18da7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (b) MDS map of group centroids (EN, JP-LLM, JP-HUMAN) using aligned embeddings (first model)\n",
    "first_model = MODELS[0][0]\n",
    "X = aligned[first_model]\n",
    "def centroid_mask(lang, trans_type=None):\n",
    "    m = (df['lang']==lang).values\n",
    "    if trans_type is not None:\n",
    "        m &= (df['trans_type']==trans_type).values\n",
    "    return m\n",
    "centroids = []\n",
    "labels = []\n",
    "m_en = centroid_mask(\"en\")\n",
    "if m_en.sum() > 0:\n",
    "    centroids.append(X[m_en].mean(0))\n",
    "    labels.append(\"EN\")\n",
    "m_llm = centroid_mask(\"ja\",\"llm\")\n",
    "if m_llm.sum() > 0:\n",
    "    centroids.append(X[m_llm].mean(0))\n",
    "    labels.append(\"JP-LLM\")\n",
    "m_hum = centroid_mask(\"ja\",\"human\")\n",
    "if m_hum.sum() > 0:\n",
    "    centroids.append(X[m_hum].mean(0))\n",
    "    labels.append(\"JP-HUMAN\")\n",
    "C = np.vstack(centroids)\n",
    "D = pairwise_distances(C, metric=\"euclidean\")\n",
    "mds = MDS(n_components=2, dissimilarity=\"precomputed\", random_state=SEED)\n",
    "Y = mds.fit_transform(D)\n",
    "fig = plt.figure(figsize=(5,5))\n",
    "plt.scatter(Y[:,0], Y[:,1])\n",
    "for i, lab in enumerate(labels):\n",
    "    plt.text(Y[i,0], Y[i,1], lab)\n",
    "plt.title(\"MDS map of centroids (first model)\")\n",
    "plt.xlabel(\"Dim 1\"); plt.ylabel(\"Dim 2\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d162f8de",
   "metadata": {},
   "source": [
    "## 11) Save outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7bed40",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = Path(\"/content/outputs\"); out_dir.mkdir(parents=True, exist_ok=True)\n",
    "res.to_csv(out_dir/\"item_metrics.csv\", index=False)\n",
    "summary_df = pd.DataFrame(summary_rows)\n",
    "summary_df.to_csv(out_dir/\"paired_tests.csv\", index=False)\n",
    "tbl = res.pivot_table(index=[\"item_id\",\"trans_type\"], columns=\"model\", values=\"kl_half\").dropna()\n",
    "models = list(tbl.columns)\n",
    "S = np.zeros((len(models), len(models)))\n",
    "for i, m1 in enumerate(models):\n",
    "    for j, m2 in enumerate(models):\n",
    "        rho, _ = spearmanr(tbl[m1], tbl[m2])\n",
    "        S[i,j] = rho\n",
    "np.savetxt(out_dir/\"spearman_matrix.txt\", S, fmt=\"%.4f\")\n",
    "with open(out_dir/\"models.json\",\"w\") as f:\n",
    "    json.dump(models, f)\n",
    "print(\"Wrote:\")\n",
    "print(\" - /content/outputs/item_metrics.csv\")\n",
    "print(\" - /content/outputs/paired_tests.csv\")\n",
    "print(\" - /content/outputs/spearman_matrix.txt\")\n",
    "print(\" - /content/outputs/models.json\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97cfb9ab",
   "metadata": {},
   "source": [
    "## 12) Extending to many scales\n",
    "- Add a `scale_id` column and **groupby** it to repeat the same logic per scale.\n",
    "- Fit **whitening & Procrustes on a larger anchor set** spanning multiple scales for stability.\n",
    "- Aggregate per-scale results and run a **random-effects meta-analysis** across scales."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}